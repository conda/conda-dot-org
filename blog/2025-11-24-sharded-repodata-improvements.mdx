---
title: "conda-forge users will soon get a 10x speed-up with conda"
slug: "sharded-repodata-improvements"
authors: [travishathaway]
tags: [conda, performance]
description: "Using conda-forge with conda is now significantly faster with improvements made to repodata fetching. Learn how we did it and who helped along the way."
image: img/blog/2025-11-24-sharded-repodata-improvements/banner.jpg
---
import Plot from '@site/src/components/Plot';

<div style={{color: "#555"}}>
<em>Photo from <a href="https://unsplash.com/de/@scar_tissue?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">
  Scar Tissue
</a> on <a href="https://unsplash.com/de/fotos/zerbrochenes-glas-mit-dunklem-verschwommenem-hintergrund-04jpFiARLmY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a></em>
</div>

<br />

How are we doing this? With a new feature called "sharded repodata",
that improves the overall speed of conda when using the [conda-forge](https://conda-forge.org)
channel. This month we're announcing the beta release of this feature, and in this post, we'll talk
about how you can try it out, how it came to be, and most importantly how much faster this makes
conda.

<!-- truncate -->

## How do I try it out?

If you're using conda-forge with conda and would like to try out this new feature, first update
`conda-libmamba-solver` in your `base` environment and then opt in to the feature by setting
`plugins.use_sharded_repodata = true`:

```bash
conda install --name base 'conda-libmamba-solver>=25.11.0'
conda config --set plugins.use_sharded_repodata true
```
## Background and context

In this section, we provide some context around why we decided to develop this feature. We
think it'll help you understand the performance metrics better, but if you already know
the ins and outs of how conda stores and uses metadata about its packages, feel free to skip
ahead to the <a href="#performance-improvements">Performance improvements</a> section.

### What's repodata?

Repodata is a conda specific term that refers to the package index that all conda clients must
download in order to find and install available packages. The best way to think about it is as
small database containing all package metadata for a particular channel.

### What's wrong with how it currently works?

Historically, all of the package metadata has been stored in a single file, and when the channel is
relatively small in size (e.g. Anaconda's "main" channel) this works pretty well. But, for larger
channels like conda-forge, this has meant longer and longer download times for users as this
channel has continued to grow over the years.

### How was this fixed?

The sluggishness of downloading large repodata files particularly annoyed the developers
of the [pixi](https://pixi.sh) package manager who were highly motivated to create a fast experience
for their users. That's why they led the drafting and development of an entirely new method for
downloading repodata: sharded repodata.

Sharded repodata takes a different approach by splitting up the large repodata into multiple "shards".
After making these improvements to the pixi package manager, pixi only had to download what the repodata
it needed to download and install requested packages. For more information on exactly how this approach
works, please see [CEP-16](https://conda.org/learn/ceps/cep-0016).

### What did this mean for conda?

The conda maintainers were impressed by the [improvements seen in pixi](https://prefix.dev/blog/sharded-repodata)
and wanted to bring this same fast experience to users of conda. So, earlier this year we began development
of our own sharded repodata implementation in Python for the [conda-libmamba-solver](https://github.com/conda/conda-libmamba-solver).

In the next section, we share the performance improvements we've seen so far.

## Performance improvements

To compare the performance improvements between the sharded and traditional approach, we used two different
environment creation scenarios: **python** and **data science**. The python scenario just fetches the package
`python` and the data science scenario fetches the packages, `pandas`, `plotly` and `scipy`. We benchmarked
just the repodata fetching itself (check out the [script we used](https://github.com/travishathaway/perfpy-conda/blob/d749765e1c124fb518784a7a2d91f3748bd32c8c/scripts/sharded_repodata_fetching.py)).


:::info
We used a special, experimental **conda-forge-sharded** channel because at the time of
profiling, sharded repodata was not available on conda-forge.

The benchmarks were also run inside a `linux/arm64` Docker container running on an Apple M1 Pro.
:::

Furthermore, we also ran our comparison using a **cold** cache where nothing was present in conda's
cache and everything was fetched via network requests and a **warm** cache where very few if any
network requests were necessary.

To get a complete picture of how these changes affected conda, we not only measured **total time**
but total **network bandwidth** usage and **maximum memory usage**.

### Total time

Below are the comparisons between traditional and sharded fetching measuring **total time**.

#### Total time with cold cache

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [21.471660, 22.360671],
      type: 'bar',
      name: 'Traditional',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [2.012411, 2.844390],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Total time with cold cache (in seconds)',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Time (seconds)' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Total time with warm cache

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [10.246788, 11.268202],
      type: 'bar',
      name: 'Traditional',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [0.670952, 1.012970],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Total time with warm cache (in seconds)',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Time (seconds)' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Key takeaways

- Under both scenarios, we see a 10x speed-up in fetching and parsing of repodata
- This happens because the size of the repodata is significantly smaller

:::info
The nature of how shards are stored also means that the cache itself is invalidated less often
(see [CEP-16](https://conda.org/learn/ceps/cep-0016#repodata-shard) for more information).
This means that conda-forge users will use the faster "warm" cache scenario more and
will spend less time downloading repodata to install the packages they want.
:::

### Network bandwidth

To further illustrate the improvements, we show the total amount of megabytes downloaded
with sharded versus the traditional approach.

#### Total network bandwidth (MB received)

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [69.653928, 69.640596],
      type: 'bar',
      name: 'Traditional',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [1.303697, 1.974313],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Total network bandwidth (MB received)',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Megabytes' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Key takeaways

- The sharded approach reduces the amount downloaded by a factor 35!
- Traditional fetching always has to fetch the same sized repodata where
  sharded repodata only fetches what it needs, meaning it varies as seen
  here.

### Max memory usage

The last metric we examine is the maximum memory usage of sharded repodata fetching. Here,
we just show the "cold" cache scenario.

#### Max memory usage (in MB)

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [1646.201823, 1642.479167],
      type: 'bar',
      name: 'Traditional',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [93.873698, 110.200521],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Max memory usage (in MB)',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Megabytes' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Key takeaways

- Both package scenarios see significant decreases in memory usage with a 15x
  and 17x reduction in memory usage.

### Conclusion

We're excited to see these numbers and think this will translate to a better overall experience
for conda-forge users! If you've read this far, we hope you're convinced to give the beta release
a try and welcome any feedback you may have. Please file an issue at the
[conda-libmamba-solver](https://github.com/conda/conda-libmamba-solver/issues) repository on GitHub
to reach out to us.

Finally, we want to give a big shout out to the conda-maintainers team and specifically
[Daniel Holth](https://github.com/dholth) for making the addition of this feature possible!

:::info
If you're interested in how we generated the profiling data we've presented, please checkout
the **[perfpy-conda](https://github.com/travishathaway/perfpy-conda)** and the
**[perfpy](https://github.com/travishathaway/perfpy)** tool.
:::
