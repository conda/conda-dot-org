---
title: "Conda-forge users will soon get a 2x speed-up with conda"
slug: "sharded-repodata-improvements"
authors: [travishathaway]
tags: [conda, performance]
description: "Using conda-forge with conda is now significantly faster with improvements made to repodata fetching. Learn how we did it and who helped along the way."
image: img/blog/2025-11-24-sharded-repodata-improvements/banner.jpg
---
import Plot from '@site/src/components/Plot';

<div style={{color: "#555"}}>
<em>Photo from <a href="https://unsplash.com/de/@scar_tissue?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">
  Scar Tissue
</a> on <a href="https://unsplash.com/de/fotos/zerbrochenes-glas-mit-dunklem-verschwommenem-hintergrund-04jpFiARLmY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a></em>
</div>

<br />

How are we doing this? With a new feature called "sharded repodata",
that improves the overall speed of conda when using the [conda-forge](https://conda-forge.org)
channel. This month we're announcing the beta release of this feature, and in this post, we'll talk
about how you can try it out, how it came to be, and most importantly how much faster this makes
conda.

<!-- truncate -->

## How do I try it out?

If you're using conda-forge with conda and would like to try out this new feature, first update
`conda-libmamba-solver` in your `base` environment and then opt in to the feature by setting
`plugins.use_sharded_repodata = true`:

```bash
conda install --name base 'conda-libmamba-solver>=25.11.0'
conda config --set plugins.use_sharded_repodata=true
```
## Background and context

In this section, we provide some context around why we decided to develop this feature. We
think it'll help you understand the performance metrics better, but if you already know
the ins and outs of how conda stores and uses metadata about its packages, feel free to skip
ahead to the <a href="#performance-improvements">Performance improvements</a> section.

### What's repodata?

Repodata is a conda specific term that refers to the package index that all conda clients must
download in order to find and install available packages. The best way to think about it is as
small database containing all package metadata for a particular channel.

### What's wrong with how it currently works?

Historically, all of the package metadata has been stored in a single file, and when the channel is
relatively small in size (e.g. Anaconda's "main" channel) this works pretty well. But, for larger
channels like conda-forge, this has meant longer and longer download times for users as this
channel has continued to grow over the years.

### How was this fixed?

The sluggishness of downloading large repodata files particularly annoyed the developers
of the [pixi](https://pixi.sh) package manager who were highly motivated to create a fast experience
for their users. That's why they led the drafting and development of an entirely new method for
downloading repodata: sharded repodata.

Sharded repodata takes a different approach by splitting up the large repodata into multiple "shards".
Clients then only download what they need in order download and install needed packages for users.
For more information on exactly how this approach works, please see
[CEP-16](https://conda.org/learn/ceps/cep-0016).

### What this meant for conda?

The conda maintainers were impressed by the [improvements seen in pixi](https://prefix.dev/blog/sharded-repodata)
and wanted to bring this same fast experience to users of conda. So, earlier this we began development
of our own sharded repodata implementation in Python for the [conda-libmamba-solver](https://github.com/conda/conda-libmamba-solver).

In the next section, we share the performance improvements we've seen so far.

## Performance improvements

To compare the performance improvements between the sharded and traditional approach, we used two different
environment creation scenarios: **python** and **data science**. The commands we used including the packages
installed are shown below:

```bash
# Simply install Python
conda create \
  --name profile-env \
  --channel conda-forge-sharded \
  python

# Installs a few "data science" packages
conda create \
  --name profile-env \
  --channel conda-forge-sharded \
  pandas plotly scipy
```

:::info
We used a special, experimental **conda-forge-sharded** channel because at the time of
profiling, sharded repodata was not available on conda-forge
:::

Furthermore, we also ran our comparison using a **cold** cache where nothing was present in conda's
cache and everything was fetched via network requests and a **warm** cache where very few if any
network requests were necessary.

To get a complete picture of how these changes affected conda, we not only measured **total time**
but total **network bandwidth** usage and **maximum memory usage** too.

### Total time

Below are the comparisons between traditional and sharded fetching measuring **total time**.

#### Total time with cold cache

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [11.733875, 18.604614],
      type: 'bar',
      name: 'Traditional',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [7.723435, 14.392441],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Total time with cold cache',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Time (seconds)' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Total time with warm cache

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [7.381542, 10.911544],
      type: 'bar',
      name: 'Traditional',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [3.023410, 5.699486],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Total time with warm cache',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Time (seconds)' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Key takeaways

- Best improvements seen in **warm** cache fetching with an overall **2x speed-up**
- For **cold** cache scenarios, sharded repodata fetching still provides users with
  a **four second speed-up**

:::info
The nature of how shards are stored also means that the cache itself is invalidated less
(see [CEP-16](https://conda.org/learn/ceps/cep-0016#repodata-shard) for more information).
This means that conda-forge users will use the "warm" cache scenario more and
will spend less time downloading repodata to install the packages they want.
:::

### Network bandwidth

To further illustrate the improvements, we show the total amount of megabytes downloaded
with sharded versus the traditional approach.

#### Total network bandwidth (MB received)

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [93.776996, 144.226861],
      type: 'bar',
      name: 'Traditional',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [53.575599, 104.768295],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Total network bandwidth (MB received)',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Megabytes' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Key takeaways

- Sharded repodata offers about a 42% and 27% reduction in network bandwidth versus
  traditional repodata fetching for the "python" and "data science" scenarios, respectively.

### Max memory usage

The last metric we examine is the maximum memory usage of the running conda process. Here,
we just show the "warm" cache scenarios because the statistics reported by the difference
between warm wasn't very significant.

#### Max memory usage (in MB)

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [794.779948, 789.205729],
      type: 'bar',
      name: 'Traditional',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [190.153646, 199.738281],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Max memory usage (in MB)',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Megabytes' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Key takeaways

- Both package scenarios see significant decreases in memory usage with about a **75% reduction**

### Conclusion

We're excited to see these numbers and think this will translate to a better overall experience
for conda-forge users! If you've read this far, we hope you're convinced to give the beta release
a try and welcome any feedback you may have. Please file an issue at the
[conda-libmamba-solver](https://github.com/conda/conda-libmamba-solver/issues) to reach out to us.

Finally, we want to give a big shout out to the conda maintainer team and specifically
[Daniel Holth](https://github.com/dholth) for making the addition of this feature possible!

:::info
If you're interested in how we generated the profiling data we've presented, please checkout
the **[perfpy-conda](https://github.com/travishathaway/perfpy-conda)** and the
**[perfpy](https://github.com/travishathaway/perfpy)** tool.
:::
