---
title: "Sharded repodata in conda (beta): an order of magnitude faster fetching"
slug: "sharded-repodata-improvements"
authors: [travishathaway]
tags: [conda, performance]
description: "Conda fetches repodata files much faster now. Learn how we did it and who helped along the way."
image: img/blog/2025-12-04-sharded-repodata-improvements/banner.jpg
---
import Plot from '@site/src/components/Plot';

<div style={{color: "#555"}}>
<em>Photo from <a href="https://unsplash.com/de/@scar_tissue?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">
  Scar Tissue
</a> on <a href="https://unsplash.com/de/fotos/zerbrochenes-glas-mit-dunklem-verschwommenem-hintergrund-04jpFiARLmY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a></em>
</div>

<br />

We're excited to announce a new beta feature in conda called sharded repodata. This optimized repodata format makes **environment solves faster** by reducing the time spent fetching package metadata.
[Conda-forge](https://conda-forge.org) is already serving sharded repodata, so you can try it immediately when using conda with conda-forge.
In this post, we'll show you how to enable it, explain how the work came together across the ecosystem, and share the performance improvements you can expect in everyday use.

<!-- truncate -->

## How do I try it out?

If you're using conda-forge with conda and would like to try out this new feature, first update
`conda-libmamba-solver` in your `base` environment and then opt in to the feature by setting
`plugins.use_sharded_repodata = true`:

```bash
conda install --name base 'conda-libmamba-solver>=25.11.0'
conda config --set plugins.use_sharded_repodata true
```
## Background and context

In this section, we provide some context around why we decided to develop this feature. We
think it'll help you understand the performance metrics better, but if you already know
the ins and outs of how conda stores and uses metadata about its packages, feel free to skip
ahead to the <a href="#performance-improvements">Performance improvements</a> section.

### What's repodata?

Repodata is a conda specific term that refers to the package index that all conda clients must
download in order to find and install available packages. The best way to think about it is as
small database containing all package metadata for a particular channel.

### Repodata challenge at scale

Channels distribute repodata as a single file. As channels add more packages, that file grows.
For channels with tens of thousands of packages, like conda-forge, that single file repodata
becomes a bottleneck. It takes longer to download and requires more memory to parse. When
anything in the channel updates, the entire cache invalidates. Conda re-downloads the complete
file just to get the latest metadata. All of this leads to a slow experience for users.

### Addressing this challenge

There have been several attempts to address this problem over the past six years, including
[reducing the size of repodata.json](https://www.anaconda.com/blog/how-we-made-conda-faster-4-7) and
[incrementally updating repodata by patching](https://conda.org/blog/2023-05-05-how-we-reduced-the-conda-index-fetch-bandwidth/#ship-repodatajlap-incremental-repodata).
Both of these previous attempts to make repodata fetching more efficient still weren't as performant
as they could be. This led [Bas Zalmstra](https://github.com/baszalmstra) and
[Wolf Vollprecht](https://github.com/wolfv) at [prefix.dev](https://prefix.dev) to design and
implement a new approach. Bas authored [CEP 16](https://conda.org/learn/ceps/cep-0016), with input
from the entire conda community, defining a new mechanism for fetching repodata using a sharded approach.

This approach works by splitting up the large repodata into multiple "shards". Each package has its
own shard which is much smaller than the total repodata. So, when a package is installed, we only
need to fetch what we need. This results in a much smaller download size and a faster overall experience.

### Sharded repodata in the wider ecosystem

[CEP 16](https://conda.org/learn/ceps/cep-0016) was authored by [Bas Zalmstra](https://github.com/baszalmstra)
at prefix.dev, reviewed by the conda community, and approved by the conda Steering Council in July 2024.
For a deep dive into the technical design and motivation, see the
[prefix.dev blog post on sharded repodata](https://prefix.dev/blog/sharded_repodata).

Since the CEP was approved, [Pixi](https://pixi.sh), [rattler](https://github.com/conda/rattler),
and [rattler-build](https://github.com/prefix-dev/rattler-build) have all provided production-ready
implementations of sharded repodata. The [prefix.dev channels](https://prefix.dev/channels) have
supported CEP 16 from day one, giving Pixi and rattler users the benefits of faster metadata
fetching for over a year.

Now that [anaconda.org](https://anaconda.org) also serves sharded repodata for conda-forge, even more
users across the ecosystem will benefit. This is also great news for conda-forge maintainers using
rattler-build: faster repodata fetching means reduced build times in CI.

This collaborative effort across multiple organizations—prefix.dev, Anaconda, Quansight, and the
conda-forge community—demonstrates how the conda ecosystem can work together to deliver meaningful
improvements for everyone.

### Bringing sharded repodata to conda

With CEP 16 already proven in production by Pixi and rattler, we've been doing the work needed to
bring the same benefits to conda users.

- Earlier this year, we updated [conda-index](https://github.com/conda/conda-index/blob/main/CHANGELOG.md#060-2025-03-27)
  so channels can generate sharded repodata.
- Most recently, we added support in [conda-libmamba-solver](https://github.com/conda/conda-libmamba-solver/releases/tag/25.11.0),
  now in beta, so the conda CLI can consume the new repodata format.
- The [anaconda.org](https://anaconda.org) team at Anaconda, with contributions from
  [Quansight](https://quansight.com), worked with the conda-forge community to enable hosting of
  sharded repodata. We plan to work with other channels to add support as the beta progresses.

With all of this in place, conda-forge is now publishing sharded repodata, and conda will use it automatically
as soon as you enable the feature.

In the next section, we share the performance improvements we've seen so far.

## Performance improvements

To compare the performance improvements between the sharded and non-sharded approach, we used two different
environment creation scenarios: **Python** and **Data Science**. The Python scenario just fetches the package
`python` and the Data Science scenario fetches the packages, `pandas`, `plotly` and `scipy`. We benchmarked
just the repodata fetching itself (check out the script we used
[here](https://github.com/travishathaway/perfpy-conda/blob/d749765e1c124fb518784a7a2d91f3748bd32c8c/scripts/sharded_repodata_fetching.py)).


:::info
We used a special, experimental **conda-forge-sharded** channel because at the time of
profiling, sharded repodata was not available on conda-forge via anaconda.org.

The benchmarks were also run inside a `linux/arm64` Docker container running on an Apple M1 Pro.
:::

Furthermore, we also ran our comparison using a **cold** cache where nothing was present in conda's
cache and everything was fetched via network requests and a **warm** cache where very few if any
network requests were necessary.

To get a complete picture of how these changes affected conda, we not only measured **total time**
but total **network bandwidth** usage and **maximum memory usage**.

### Total time

Below are the comparisons between non-sharded and sharded fetching measuring **total time**.

#### Total time with cold cache

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [21.471660, 22.360671],
      type: 'bar',
      name: 'Non-sharded',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [2.012411, 2.844390],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Total time with cold cache (in seconds)',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Time (seconds)' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Total time with warm cache

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [10.246788, 11.268202],
      type: 'bar',
      name: 'Non-sharded',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [0.670952, 1.012970],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Total time with warm cache (in seconds)',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Time (seconds)' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Key takeaways

- Under both scenarios, we see a 10x speed-up in fetching and parsing of repodata
- This happens because the size of the repodata is significantly smaller

:::info
The nature of how shards are stored also means that the cache itself is invalidated less
(see [CEP 16](https://conda.org/learn/ceps/cep-0016#repodata-shard) for more information).
This means that conda-forge users will use the faster "warm" cache scenario more and
will spend less time downloading repodata to install the packages they want.
:::

### Network bandwidth

To further illustrate the improvements, we show the total amount of megabytes downloaded
with sharded versus the non-sharded approach.

#### Total network bandwidth (MB received)

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [69.653928, 69.640596],
      type: 'bar',
      name: 'Non-sharded',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [1.303697, 1.974313],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Total network bandwidth (MB received)',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Megabytes' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Key takeaways

- The sharded approach reduces the amount downloaded by a factor 35!
- Non-sharded fetching always has to fetch the same sized repodata where
  sharded repodata only fetches what it needs, meaning it varies as seen
  here.

### Max memory usage

The last metric we examine is the maximum memory usage of sharded repodata fetching. Here,
we just show the "cold" cache scenario.

#### Max memory usage (in MB)

<Plot
  data={[
    {
      x: ['Python', 'Data science'],
      y: [1646.201823, 1642.479167],
      type: 'bar',
      name: 'Non-sharded',
      marker: { color: '#e74c3c' },
    },
    {
      x: ['Python', 'Data science'],
      y: [93.873698, 110.200521],
      type: 'bar',
      name: 'Sharded',
      marker: { color: '#2ecc71' },
    },
  ]}
  layout={{
    title: 'Max memory usage (in MB)',
    xaxis: { title: 'Package Scenario' },
    yaxis: { title: 'Megabytes' },
    barmode: 'group',
    height: 500,
  }}
/>

#### Key takeaways

Both package scenarios see significant decreases in memory usage with a 15x
and 17x reduction in memory usage.

### Conclusion

We're excited to see these numbers and think this will translate to a better overall experience
for conda users! If you've read this far, we hope you're convinced to give the beta release
a try and welcome any feedback you may have. Please file an issue at the
[conda-libmamba-solver](https://github.com/conda/conda-libmamba-solver/issues) repository on GitHub
to reach out to us.

Finally, we want to give a big shout out to the conda-maintainers team and specifically
[Daniel Holth](https://github.com/dholth) for making the addition of this feature possible!

:::info
If you're interested in how we generated the profiling data we've presented, please checkout
the **[perfpy-conda](https://github.com/travishathaway/perfpy-conda)** and the
**[perfpy](https://github.com/travishathaway/perfpy)** tool.
:::
