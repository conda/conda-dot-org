#! /usr/bin/env python
"""
This is a script to help us keep our "blog/news.json" file up to
date. It will scan the "blog" directory, sort items by date (which
is just title) and then read the metadata from the entries to update
the "news.json" file.
"""

from __future__ import annotations

import datetime
import json
import os
import pathlib
import re
from typing import Any, Iterator, Sequence

from ruamel.yaml import YAML

#: Directory where blog posts are located
BLOGS_DIR = pathlib.Path("./blog")

#: Location of the news file
NEWS_FILE = BLOGS_DIR.joinpath("news.json")

#: Matches anything that begins with a time stamp (e.g. 2023-03-23-something)
BLOGS_TITLE_PAT = re.compile(r"([0-9]{4}-[0-9]{2}-[0-9]{2})(.+)")


def has_blog_title_pattern(item: str) -> bool:
    """
    Filter that checks whether the file or directory has the pattern we want
    (see the above regex for more information).

    Example:
        - 2023-04-02-blog-post.md
        - 2023-04-04-another-post/
    """
    match = BLOGS_TITLE_PAT.match(item)

    return match is not None


def has_index_file_ending(item: pathlib.Path) -> bool:
    """
    Checks to see if the file ends with a *.md or *.mdx
    """
    return item.name.lower() in ("index.md", "index.mdx")


def get_blog_files() -> tuple[str]:
    """
    Returns all the blog files that we need to include in the "news.json" file.
    This is only the five newest according to the date in the title.
    """
    blogs_listing = tuple(
        BLOGS_DIR.joinpath(item)
        for item in filter(has_blog_title_pattern, os.listdir(BLOGS_DIR))
    )
    blogs_dirs = filter(os.path.isdir, blogs_listing)
    blogs_files = filter(os.path.isfile, blogs_listing)

    blogs_dirs_files = (
        pathlib.Path(dir).joinpath(item)
        for dir in blogs_dirs
        for item in os.listdir(dir)
        if has_index_file_ending(pathlib.Path(item))
    )

    return sorted(
        tuple(blogs_files) + tuple(blogs_dirs_files),
        reverse=True,
        key=lambda item: item.name,
    )[:5]


def get_date_from_filename(filename: str) -> datetime.datetime | None:
    """
    Parses a datetime object from a str that has a date string in it that
    looks like "YYYY-MM-DD".
    """
    rest, base = os.path.split(filename)

    if has_index_file_ending(filename):
        base = os.path.basename(rest)

    pat_match = BLOGS_TITLE_PAT.match(base)

    if pat_match:
        date_str = pat_match.group(1)
        return datetime.datetime.strptime(date_str, "%Y-%m-%d")


def get_file_data(files: Sequence[str]) -> Iterator[dict[str, Any]]:
    """
    Reads the file and returns the data contained within the frontmatter.
    """
    for idx, file in enumerate(files):
        with open(file, "r") as handle:
            parts = handle.read().split("---")
            if len(parts) > 1:
                yml_part = parts[1]
                yml_part = yml_part.strip("\n")
                yml_obj = YAML().load(yml_part)
                date = get_date_from_filename(file)
                if date is not None:
                    yield {**yml_obj, "date": date.isoformat()}


def main():
    blog_files = get_blog_files()
    file_data = tuple(get_file_data(blog_files))

    with NEWS_FILE.open("w") as handle:
        json.dump(file_data, handle, indent=2)


if __name__ == "__main__":
    main()
